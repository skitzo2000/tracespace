# gerber/drill lexer

> Lenient tokenizer for Gerber and drill files

The lexing module of @tracespace/parser can be imported directly:

```js
// commonjs
const {createLexer} = require('@tracespace/parser')

// modules
import {createLexer} from '@tracespace/parser'
```

## usage

The lexer is generated by [moo][], which determines its API.

```js
import {createLexer} from '@tracespace/parser'

const lexer = createLexer()

lexer.reset(/* ...some gerber string... */)

Array.from(lexer).forEach(token => {
  console.log(`${token.type}: ${token.value}`)
})
```

[moo]: https://github.com/no-context/moo

### typescript usage

```ts
import {createLexer, Lexer, Token, TokenType} from '@tracespace/parser'

const lexer: Lexer = createLexer()

lexer.reset(/* ...some gerber string... */)

Array.from(lexer).forEach((token: Token) => {
  const type: TokenType = token.type
  const value: string = token.value

  console.log(`${type}: ${value}`)
})
```

## api

### createLexer(): Lexer

```js
import {createLexer} from '@tracepsace/parser'

const lexer = createLexer()
```

A [`Lexer`](#Lexer) is stateful, so be sure to create a new Lexer for every file if processing in parallel or call `lexer.reset()` between files if processing serially.

### Lexer

```ts
// typescript
import {Lexer} from '@tracespace/parser'
```

| method                        | return                               | description                                                                           |
| ----------------------------- | ------------------------------------ | ------------------------------------------------------------------------------------- |
| `lexer.next()`                | [`Token`](#Token) &vert; `undefined` | Returns the next token or `undefined` if the lexer's internal buffer is empty         |
| `lexer.reset(chunk?: string)` | `void`                               | Set the internal buffer of the lexer to `chunk` and reset the character/line counters |

### Token

```ts
// typescript
import {Token} from '@tracespace/parser'
```

| property           | type                      | description                                          |
| ------------------ | ------------------------- | ---------------------------------------------------- |
| `token.type`       | [`TokenType`](#TokenType) | Type identifier                                      |
| `token.value`      | `string`                  | Match contents                                       |
| `token.offset`     | `number`                  | Match start index in buffer                          |
| `token.text`       | `string`                  | Complete, unprocessed token match                    |
| `token.lineBreaks` | `number`                  | Number of line breaks found in the match             |
| `token.line`       | `number`                  | Line number of the match, starting at 1              |
| `token.col`        | `number`                  | Column in line where the match begins, starting at 1 |

### TokenType

```ts
// typescript
import {TokenType} from '@tracespace/parser'
```

`TokenType` is a union of all available string types. All type constants are also exported by the module.

```js
import {
  T_CODE,
  G_CODE,
  M_CODE,
  D_CODE,
  ASTERISK,
  PERCENT,
  GERBER_FORMAT,
  GERBER_UNITS,
  GERBER_TOOL_DEF,
  GERBER_TOOL_NAME,
  DRILL_COMMENT,
  DRILL_UNITS,
  DRILL_ZERO_INCLUSION,
  DRILL_COORD_FORMAT,
  DRILL_TOOL_PROPS,
  COORD_CHAR,
  NUMBER,
  WORD,
  WHITESPACE,
  NEWLINE,
  CATCHALL,
  ERROR,
} from '@tracespace/parser'
```
